{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0f42f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import torch, torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "#from torchsummary import summary\n",
    "\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]='True'\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdbfcf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transforms = { \n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21476156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Dr. Bhavanishankar K\\\\Desktop\\\\Cotton_data'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir=\"C:\\\\Users\\\\Dr. Bhavanishankar K\\\\Desktop\\\\Cotton_data\"\n",
    "dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f47a8bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "{0: 'Aphids', 1: 'Bacterial blight', 2: 'Cotton Boll Rot', 3: 'Healthy', 4: 'Powdery mildew'}\n"
     ]
    }
   ],
   "source": [
    "dataset = \"C:\\\\Users\\\\Dr. Bhavanishankar K\\\\Desktop\\\\Cotton_data\"\n",
    "\n",
    "train_directory = os.path.join(dataset, 'train')\n",
    "valid_directory = os.path.join(dataset, 'valid')\n",
    "\n",
    "# Batch size\n",
    "bs = 32\n",
    "\n",
    "# Number of classes\n",
    "num_classes = len(os.listdir(valid_directory))  \n",
    "print(num_classes)\n",
    "\n",
    "# Load Data from folders\n",
    "data = {\n",
    "    'train': datasets.ImageFolder(root=train_directory, transform=image_transforms['train']),\n",
    "    'valid': datasets.ImageFolder(root=valid_directory, transform=image_transforms['valid'])\n",
    "}\n",
    "\n",
    "# Get a mapping of the indices to the class names, in order to see the output classes of the test images.\n",
    "idx_to_class = {v: k for k, v in data['train'].class_to_idx.items()}\n",
    "print(idx_to_class)\n",
    "\n",
    "# Size of Data, to be used for calculating Average Loss and Accuracy\n",
    "train_data_size = len(data['train'])\n",
    "valid_data_size = len(data['valid'])\n",
    "\n",
    "# Create iterators for the Data loaded using DataLoader module\n",
    "train_data_loader = DataLoader(data['train'], batch_size=bs, shuffle=True)\n",
    "valid_data_loader = DataLoader(data['valid'], batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35731c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4160, 217)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_size, valid_data_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee967418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: efficientnet_pytorch in c:\\users\\dr. bhavanishankar k\\anaconda3\\lib\\site-packages (0.7.1)\n",
      "Requirement already satisfied: torch in c:\\users\\dr. bhavanishankar k\\anaconda3\\lib\\site-packages (from efficientnet_pytorch) (2.1.2+cu121)\n",
      "Requirement already satisfied: filelock in c:\\users\\dr. bhavanishankar k\\anaconda3\\lib\\site-packages (from torch->efficientnet_pytorch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\dr. bhavanishankar k\\anaconda3\\lib\\site-packages (from torch->efficientnet_pytorch) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\dr. bhavanishankar k\\anaconda3\\lib\\site-packages (from torch->efficientnet_pytorch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\dr. bhavanishankar k\\anaconda3\\lib\\site-packages (from torch->efficientnet_pytorch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dr. bhavanishankar k\\anaconda3\\lib\\site-packages (from torch->efficientnet_pytorch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\dr. bhavanishankar k\\anaconda3\\lib\\site-packages (from torch->efficientnet_pytorch) (2023.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dr. bhavanishankar k\\anaconda3\\lib\\site-packages (from jinja2->torch->efficientnet_pytorch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\dr. bhavanishankar k\\anaconda3\\lib\\site-packages (from sympy->torch->efficientnet_pytorch) (1.3.0)\n",
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (_conv_stem): Conv2dStaticSamePadding(\n",
       "    3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "    (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "  )\n",
       "  (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
       "        (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 2, 1, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (6-7): 2 x MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (9-10): 2 x MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 2, 1, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (12-14): 3 x MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dStaticSamePadding(\n",
       "    320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "    (static_padding): Identity()\n",
       "  )\n",
       "  (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "  (_dropout): Dropout(p=0.2, inplace=False)\n",
       "  (_fc): Linear(in_features=1280, out_features=5, bias=True)\n",
       "  (_swish): MemoryEfficientSwish()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install efficientnet_pytorch\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import torch\n",
    "\n",
    "# Load pre-trained EfficientNet\n",
    "efficientnet = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "\n",
    "# Freeze the pre-trained parameters\n",
    "for param in efficientnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the last fully connected layer to match your task\n",
    "num_ftrs = efficientnet._fc.in_features\n",
    "efficientnet._fc = torch.nn.Linear(num_ftrs, num_classes)  # Replace num_classes with the number of classes in your dataset\n",
    "\n",
    "# Now, your efficientnet model is ready for use\n",
    "efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "204bca8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in efficientnet.parameters():\n",
    "    param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d152b863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (_conv_stem): Conv2dStaticSamePadding(\n",
       "    3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "    (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "  )\n",
       "  (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
       "        (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 2, 1, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (6-7): 2 x MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (9-10): 2 x MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 2, 1, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (12-14): 3 x MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dStaticSamePadding(\n",
       "    320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "    (static_padding): Identity()\n",
       "  )\n",
       "  (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "  (_dropout): Dropout(p=0.2, inplace=False)\n",
       "  (_fc): Linear(in_features=1280, out_features=5, bias=True)\n",
       "  (_swish): MemoryEfficientSwish()\n",
       "  (7): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_ftrs = efficientnet._fc.in_features\n",
    "efficientnet._fc = nn.Linear(num_ftrs, 5)  # Replace num_classes with the number of classes in your dataset\n",
    "\n",
    "# Add LogSoftmax layer\n",
    "efficientnet.add_module(\"7\", nn.LogSoftmax(dim=1))\n",
    "\n",
    "# Now, your EfficientNet model is ready for use\n",
    "efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4796005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.001\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Define the loss function\n",
    "loss_func = nn.NLLLoss()\n",
    "\n",
    "# Define the optimizer for EfficientNet parameters\n",
    "optimizer = optim.Adam(efficientnet.parameters())\n",
    "\n",
    "# Now, your optimizer is ready for use with the EfficientNet model\n",
    "optimizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c765232c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(model, loss_criterion, optimizer, epochs):\n",
    "    '''\n",
    "    Function to train and validate\n",
    "    Parameters\n",
    "        :param model: Model to train and validate\n",
    "        :param loss_criterion: Loss Criterion to minimize\n",
    "        :param optimizer: Optimizer for computing gradients\n",
    "        :param epochs: Number of epochs (default=25)\n",
    "  \n",
    "    Returns\n",
    "        model: Trained Model with best validation accuracy\n",
    "        history: (dict object): Having training loss, accuracy and validation loss, accuracy\n",
    "    '''\n",
    "    \n",
    "    start = time.time()\n",
    "    history = []\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "        print(\"Epoch: {}/{}\".format(epoch+1, epochs))\n",
    "        \n",
    "        # Set to training mode\n",
    "        model.train()\n",
    "        \n",
    "        # Loss and Accuracy within the epoch\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        \n",
    "        valid_loss = 0.0\n",
    "        valid_acc = 0.0\n",
    "        \n",
    "        for i, (inputs, labels) in enumerate(train_data_loader):\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Clean existing gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass - compute outputs on input data using the model\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = loss_criterion(outputs, labels)\n",
    "            \n",
    "            # Backpropagate the gradients\n",
    "            loss.backward()\n",
    "            \n",
    "            # Update the parameters\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Compute the total loss for the batch and add it to train_loss\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            # Compute the accuracy\n",
    "            ret, predictions = torch.max(outputs.data, 1)\n",
    "            correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "            \n",
    "            # Convert correct_counts to float and then compute the mean\n",
    "            acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "            \n",
    "            # Compute total accuracy in the whole batch and add to train_acc\n",
    "            train_acc += acc.item() * inputs.size(0)\n",
    "            \n",
    "            #print(\"Batch number: {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}\".format(i, loss.item(), acc.item()))\n",
    "\n",
    "            \n",
    "        # Validation - No gradient tracking needed\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # Set to evaluation mode\n",
    "            model.eval()\n",
    "\n",
    "            # Validation loop\n",
    "            for j, (inputs, labels) in enumerate(valid_data_loader):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Forward pass - compute outputs on input data using the model\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                # Compute loss\n",
    "                loss = loss_criterion(outputs, labels)\n",
    "\n",
    "                # Compute the total loss for the batch and add it to valid_loss\n",
    "                valid_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                # Calculate validation accuracy\n",
    "                ret, predictions = torch.max(outputs.data, 1)\n",
    "                correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "\n",
    "                # Convert correct_counts to float and then compute the mean\n",
    "                acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "\n",
    "                # Compute total accuracy in the whole batch and add to valid_acc\n",
    "                valid_acc += acc.item() * inputs.size(0)\n",
    "\n",
    "                #print(\"Validation Batch number: {:03d}, Validation: Loss: {:.4f}, Accuracy: {:.4f}\".format(j, loss.item(), acc.item()))\n",
    "            \n",
    "        # Find average training loss and training accuracy\n",
    "        avg_train_loss = train_loss/train_data_size \n",
    "        avg_train_acc = train_acc/train_data_size\n",
    "\n",
    "        # Find average training loss and training accuracy\n",
    "        avg_valid_loss = valid_loss/valid_data_size \n",
    "        avg_valid_acc = valid_acc/valid_data_size\n",
    "\n",
    "        history.append([avg_train_loss, avg_valid_loss, avg_train_acc, avg_valid_acc])\n",
    "                \n",
    "        epoch_end = time.time()\n",
    "    \n",
    "        print(\"Epoch : {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}%, \\n\\t\\tValidation : Loss : {:.4f}, Accuracy: {:.4f}%, Time: {:.4f}s\".format(epoch+1, avg_train_loss, avg_train_acc*100, avg_valid_loss, avg_valid_acc*100, epoch_end-epoch_start))\n",
    "        \n",
    "        # Save if the model has best accuracy till now\n",
    "        #torch.save(model, dataset+'_model_'+str(epoch)+'.pt')\n",
    "            \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eff1f0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/250\n",
      "Epoch : 001, Training: Loss: -21.3550, Accuracy: 82.2115%, \n",
      "\t\tValidation : Loss : -26.7349, Accuracy: 87.5576%, Time: 122.4284s\n",
      "Epoch: 2/250\n",
      "Epoch : 002, Training: Loss: -35.7478, Accuracy: 83.2933%, \n",
      "\t\tValidation : Loss : -37.7850, Accuracy: 88.4793%, Time: 121.7037s\n",
      "Epoch: 3/250\n",
      "Epoch : 003, Training: Loss: -50.0220, Accuracy: 82.4279%, \n",
      "\t\tValidation : Loss : -49.0401, Accuracy: 87.5576%, Time: 121.4186s\n",
      "Epoch: 4/250\n",
      "Epoch : 004, Training: Loss: -64.3312, Accuracy: 83.0769%, \n",
      "\t\tValidation : Loss : -60.9003, Accuracy: 85.7143%, Time: 121.4879s\n",
      "Epoch: 5/250\n",
      "Epoch : 005, Training: Loss: -78.6109, Accuracy: 84.0385%, \n",
      "\t\tValidation : Loss : -72.8120, Accuracy: 86.1751%, Time: 121.5705s\n",
      "Epoch: 6/250\n",
      "Epoch : 006, Training: Loss: -93.0150, Accuracy: 84.1106%, \n",
      "\t\tValidation : Loss : -84.9891, Accuracy: 87.0968%, Time: 121.6614s\n",
      "Epoch: 7/250\n",
      "Epoch : 007, Training: Loss: -107.1897, Accuracy: 83.0529%, \n",
      "\t\tValidation : Loss : -96.5327, Accuracy: 86.1751%, Time: 121.4322s\n",
      "Epoch: 8/250\n",
      "Epoch : 008, Training: Loss: -121.4806, Accuracy: 82.6202%, \n",
      "\t\tValidation : Loss : -108.9883, Accuracy: 85.7143%, Time: 121.3757s\n",
      "Epoch: 9/250\n",
      "Epoch : 009, Training: Loss: -135.6977, Accuracy: 83.4375%, \n",
      "\t\tValidation : Loss : -121.4107, Accuracy: 86.6359%, Time: 121.4598s\n",
      "Epoch: 10/250\n",
      "Epoch : 010, Training: Loss: -150.4042, Accuracy: 83.1971%, \n",
      "\t\tValidation : Loss : -132.8468, Accuracy: 86.1751%, Time: 121.6669s\n",
      "Epoch: 11/250\n",
      "Epoch : 011, Training: Loss: -164.1208, Accuracy: 83.0288%, \n",
      "\t\tValidation : Loss : -145.8255, Accuracy: 86.6359%, Time: 121.5336s\n",
      "Epoch: 12/250\n",
      "Epoch : 012, Training: Loss: -178.7749, Accuracy: 82.4279%, \n",
      "\t\tValidation : Loss : -158.1993, Accuracy: 86.1751%, Time: 121.4797s\n",
      "Epoch: 13/250\n",
      "Epoch : 013, Training: Loss: -192.9134, Accuracy: 83.5337%, \n",
      "\t\tValidation : Loss : -170.3327, Accuracy: 86.6359%, Time: 121.4629s\n",
      "Epoch: 14/250\n",
      "Epoch : 014, Training: Loss: -207.0357, Accuracy: 83.5096%, \n",
      "\t\tValidation : Loss : -181.7374, Accuracy: 86.6359%, Time: 121.4973s\n",
      "Epoch: 15/250\n",
      "Epoch : 015, Training: Loss: -221.3084, Accuracy: 84.1106%, \n",
      "\t\tValidation : Loss : -193.5161, Accuracy: 87.5576%, Time: 121.7048s\n",
      "Epoch: 16/250\n",
      "Epoch : 016, Training: Loss: -235.5385, Accuracy: 83.6058%, \n",
      "\t\tValidation : Loss : -205.8054, Accuracy: 86.6359%, Time: 121.6183s\n",
      "Epoch: 17/250\n",
      "Epoch : 017, Training: Loss: -249.9105, Accuracy: 84.0625%, \n",
      "\t\tValidation : Loss : -218.2357, Accuracy: 87.5576%, Time: 121.4621s\n",
      "Epoch: 18/250\n",
      "Epoch : 018, Training: Loss: -264.7455, Accuracy: 84.6394%, \n",
      "\t\tValidation : Loss : -230.0582, Accuracy: 85.7143%, Time: 121.5031s\n",
      "Epoch: 19/250\n",
      "Epoch : 019, Training: Loss: -278.3562, Accuracy: 82.8365%, \n",
      "\t\tValidation : Loss : -242.9862, Accuracy: 86.1751%, Time: 121.5417s\n",
      "Epoch: 20/250\n",
      "Epoch : 020, Training: Loss: -292.8163, Accuracy: 83.0048%, \n",
      "\t\tValidation : Loss : -254.8259, Accuracy: 86.6359%, Time: 121.7614s\n",
      "Epoch: 21/250\n",
      "Epoch : 021, Training: Loss: -306.7184, Accuracy: 83.6298%, \n",
      "\t\tValidation : Loss : -267.2754, Accuracy: 86.6359%, Time: 121.5057s\n",
      "Epoch: 22/250\n",
      "Epoch : 022, Training: Loss: -321.7269, Accuracy: 84.0385%, \n",
      "\t\tValidation : Loss : -278.6310, Accuracy: 86.6359%, Time: 121.4523s\n",
      "Epoch: 23/250\n",
      "Epoch : 023, Training: Loss: -335.7918, Accuracy: 84.6875%, \n",
      "\t\tValidation : Loss : -292.1331, Accuracy: 87.0968%, Time: 121.5145s\n",
      "Epoch: 24/250\n",
      "Epoch : 024, Training: Loss: -349.7349, Accuracy: 83.9183%, \n",
      "\t\tValidation : Loss : -304.8964, Accuracy: 87.5576%, Time: 121.4411s\n",
      "Epoch: 25/250\n",
      "Epoch : 025, Training: Loss: -364.8684, Accuracy: 83.9663%, \n",
      "\t\tValidation : Loss : -313.8405, Accuracy: 86.1751%, Time: 121.5018s\n",
      "Epoch: 26/250\n",
      "Epoch : 026, Training: Loss: -378.7425, Accuracy: 83.8221%, \n",
      "\t\tValidation : Loss : -326.4461, Accuracy: 86.6359%, Time: 121.4709s\n",
      "Epoch: 27/250\n",
      "Epoch : 027, Training: Loss: -393.7041, Accuracy: 84.0144%, \n",
      "\t\tValidation : Loss : -335.9383, Accuracy: 85.7143%, Time: 121.4954s\n",
      "Epoch: 28/250\n",
      "Epoch : 028, Training: Loss: -407.6297, Accuracy: 83.6298%, \n",
      "\t\tValidation : Loss : -347.9826, Accuracy: 86.1751%, Time: 121.5320s\n",
      "Epoch: 29/250\n",
      "Epoch : 029, Training: Loss: -421.3610, Accuracy: 84.3029%, \n",
      "\t\tValidation : Loss : -363.6384, Accuracy: 86.6359%, Time: 121.4482s\n",
      "Epoch: 30/250\n",
      "Epoch : 030, Training: Loss: -436.4736, Accuracy: 83.7740%, \n",
      "\t\tValidation : Loss : -374.4901, Accuracy: 86.1751%, Time: 121.7737s\n",
      "Epoch: 31/250\n",
      "Epoch : 031, Training: Loss: -449.7776, Accuracy: 83.2212%, \n",
      "\t\tValidation : Loss : -386.9796, Accuracy: 87.0968%, Time: 121.6117s\n",
      "Epoch: 32/250\n",
      "Epoch : 032, Training: Loss: -464.8375, Accuracy: 84.4712%, \n",
      "\t\tValidation : Loss : -398.6813, Accuracy: 87.0968%, Time: 121.4758s\n",
      "Epoch: 33/250\n",
      "Epoch : 033, Training: Loss: -478.5582, Accuracy: 83.3173%, \n",
      "\t\tValidation : Loss : -410.2893, Accuracy: 86.6359%, Time: 121.4725s\n",
      "Epoch: 34/250\n",
      "Epoch : 034, Training: Loss: -492.7354, Accuracy: 83.7019%, \n",
      "\t\tValidation : Loss : -425.4063, Accuracy: 86.1751%, Time: 121.5036s\n",
      "Epoch: 35/250\n",
      "Epoch : 035, Training: Loss: -507.1559, Accuracy: 83.7260%, \n",
      "\t\tValidation : Loss : -435.7123, Accuracy: 88.0184%, Time: 121.8063s\n",
      "Epoch: 36/250\n",
      "Epoch : 036, Training: Loss: -522.1239, Accuracy: 84.2548%, \n",
      "\t\tValidation : Loss : -450.8654, Accuracy: 86.1751%, Time: 121.5384s\n",
      "Epoch: 37/250\n",
      "Epoch : 037, Training: Loss: -535.9557, Accuracy: 83.6298%, \n",
      "\t\tValidation : Loss : -460.0662, Accuracy: 86.1751%, Time: 121.4312s\n",
      "Epoch: 38/250\n",
      "Epoch : 038, Training: Loss: -550.3433, Accuracy: 84.1106%, \n",
      "\t\tValidation : Loss : -472.6077, Accuracy: 86.6359%, Time: 121.4899s\n",
      "Epoch: 39/250\n",
      "Epoch : 039, Training: Loss: -564.9309, Accuracy: 83.7740%, \n",
      "\t\tValidation : Loss : -485.4606, Accuracy: 85.7143%, Time: 121.4630s\n",
      "Epoch: 40/250\n",
      "Epoch : 040, Training: Loss: -577.9036, Accuracy: 83.5817%, \n",
      "\t\tValidation : Loss : -497.8557, Accuracy: 86.6359%, Time: 121.7513s\n",
      "Epoch: 41/250\n",
      "Epoch : 041, Training: Loss: -593.0122, Accuracy: 83.7500%, \n",
      "\t\tValidation : Loss : -506.7552, Accuracy: 86.1751%, Time: 121.4717s\n",
      "Epoch: 42/250\n",
      "Epoch : 042, Training: Loss: -608.9868, Accuracy: 84.6635%, \n",
      "\t\tValidation : Loss : -520.6119, Accuracy: 85.7143%, Time: 121.4531s\n",
      "Epoch: 43/250\n",
      "Epoch : 043, Training: Loss: -622.4726, Accuracy: 83.4856%, \n",
      "\t\tValidation : Loss : -534.8949, Accuracy: 86.1751%, Time: 121.4507s\n",
      "Epoch: 44/250\n",
      "Epoch : 044, Training: Loss: -636.7682, Accuracy: 82.8846%, \n",
      "\t\tValidation : Loss : -547.9016, Accuracy: 86.6359%, Time: 121.4542s\n",
      "Epoch: 45/250\n",
      "Epoch : 045, Training: Loss: -649.0346, Accuracy: 84.0865%, \n",
      "\t\tValidation : Loss : -555.0731, Accuracy: 87.0968%, Time: 121.6856s\n",
      "Epoch: 46/250\n",
      "Epoch : 046, Training: Loss: -664.6306, Accuracy: 83.5577%, \n",
      "\t\tValidation : Loss : -569.5469, Accuracy: 87.5576%, Time: 121.5659s\n",
      "Epoch: 47/250\n",
      "Epoch : 047, Training: Loss: -679.4348, Accuracy: 83.5096%, \n",
      "\t\tValidation : Loss : -583.0384, Accuracy: 87.5576%, Time: 121.4612s\n",
      "Epoch: 48/250\n",
      "Epoch : 048, Training: Loss: -693.6144, Accuracy: 83.8221%, \n",
      "\t\tValidation : Loss : -598.3107, Accuracy: 87.0968%, Time: 121.4880s\n",
      "Epoch: 49/250\n",
      "Epoch : 049, Training: Loss: -707.9789, Accuracy: 85.0240%, \n",
      "\t\tValidation : Loss : -604.3896, Accuracy: 86.6359%, Time: 121.5063s\n",
      "Epoch: 50/250\n",
      "Epoch : 050, Training: Loss: -722.0536, Accuracy: 83.8702%, \n",
      "\t\tValidation : Loss : -619.4735, Accuracy: 87.0968%, Time: 121.4653s\n",
      "Epoch: 51/250\n",
      "Epoch : 051, Training: Loss: -733.6748, Accuracy: 83.9423%, \n",
      "\t\tValidation : Loss : -627.7562, Accuracy: 87.0968%, Time: 121.4234s\n",
      "Epoch: 52/250\n",
      "Epoch : 052, Training: Loss: -751.5680, Accuracy: 83.0529%, \n",
      "\t\tValidation : Loss : -641.9392, Accuracy: 87.0968%, Time: 121.5103s\n",
      "Epoch: 53/250\n",
      "Epoch : 053, Training: Loss: -764.7262, Accuracy: 83.1010%, \n",
      "\t\tValidation : Loss : -653.9481, Accuracy: 86.6359%, Time: 121.5049s\n",
      "Epoch: 54/250\n",
      "Epoch : 054, Training: Loss: -780.0462, Accuracy: 84.5673%, \n",
      "\t\tValidation : Loss : -665.3435, Accuracy: 86.6359%, Time: 121.5306s\n",
      "Epoch: 55/250\n",
      "Epoch : 055, Training: Loss: -793.9362, Accuracy: 84.0865%, \n",
      "\t\tValidation : Loss : -675.4407, Accuracy: 87.0968%, Time: 121.7160s\n",
      "Epoch: 56/250\n",
      "Epoch : 056, Training: Loss: -808.0388, Accuracy: 84.0865%, \n",
      "\t\tValidation : Loss : -686.4767, Accuracy: 86.6359%, Time: 121.5075s\n",
      "Epoch: 57/250\n",
      "Epoch : 057, Training: Loss: -820.5724, Accuracy: 84.0865%, \n",
      "\t\tValidation : Loss : -706.7915, Accuracy: 85.7143%, Time: 121.4266s\n",
      "Epoch: 58/250\n",
      "Epoch : 058, Training: Loss: -836.0982, Accuracy: 83.3654%, \n",
      "\t\tValidation : Loss : -718.5119, Accuracy: 86.1751%, Time: 121.4901s\n",
      "Epoch: 59/250\n",
      "Epoch : 059, Training: Loss: -849.3246, Accuracy: 82.9087%, \n",
      "\t\tValidation : Loss : -722.0053, Accuracy: 86.6359%, Time: 121.4954s\n",
      "Epoch: 60/250\n",
      "Epoch : 060, Training: Loss: -864.3324, Accuracy: 83.8221%, \n",
      "\t\tValidation : Loss : -731.6430, Accuracy: 86.1751%, Time: 121.6616s\n",
      "Epoch: 61/250\n",
      "Epoch : 061, Training: Loss: -879.0472, Accuracy: 83.7019%, \n",
      "\t\tValidation : Loss : -749.4861, Accuracy: 87.0968%, Time: 121.5806s\n",
      "Epoch: 62/250\n",
      "Epoch : 062, Training: Loss: -893.9552, Accuracy: 83.7981%, \n",
      "\t\tValidation : Loss : -763.2624, Accuracy: 86.1751%, Time: 121.5462s\n",
      "Epoch: 63/250\n",
      "Epoch : 063, Training: Loss: -908.7117, Accuracy: 83.8221%, \n",
      "\t\tValidation : Loss : -776.8755, Accuracy: 87.0968%, Time: 121.5239s\n",
      "Epoch: 64/250\n",
      "Epoch : 064, Training: Loss: -923.5586, Accuracy: 83.7981%, \n",
      "\t\tValidation : Loss : -787.8759, Accuracy: 86.6359%, Time: 121.4904s\n",
      "Epoch: 65/250\n",
      "Epoch : 065, Training: Loss: -935.7052, Accuracy: 83.1731%, \n",
      "\t\tValidation : Loss : -799.3519, Accuracy: 86.6359%, Time: 121.8056s\n",
      "Epoch: 66/250\n",
      "Epoch : 066, Training: Loss: -950.8826, Accuracy: 84.1587%, \n",
      "\t\tValidation : Loss : -808.2669, Accuracy: 87.0968%, Time: 121.5263s\n",
      "Epoch: 67/250\n",
      "Epoch : 067, Training: Loss: -962.1379, Accuracy: 83.3894%, \n",
      "\t\tValidation : Loss : -818.6038, Accuracy: 86.1751%, Time: 121.4577s\n",
      "Epoch: 68/250\n",
      "Epoch : 068, Training: Loss: -980.6677, Accuracy: 84.6875%, \n",
      "\t\tValidation : Loss : -836.9582, Accuracy: 85.7143%, Time: 121.4509s\n",
      "Epoch: 69/250\n",
      "Epoch : 069, Training: Loss: -993.8054, Accuracy: 84.1827%, \n",
      "\t\tValidation : Loss : -849.6330, Accuracy: 85.7143%, Time: 121.5668s\n",
      "Epoch: 70/250\n",
      "Epoch : 070, Training: Loss: -1008.3161, Accuracy: 83.7260%, \n",
      "\t\tValidation : Loss : -860.8669, Accuracy: 87.0968%, Time: 121.7375s\n",
      "Epoch: 71/250\n",
      "Epoch : 071, Training: Loss: -1018.5406, Accuracy: 83.4135%, \n",
      "\t\tValidation : Loss : -873.5894, Accuracy: 86.1751%, Time: 121.4887s\n",
      "Epoch: 72/250\n",
      "Epoch : 072, Training: Loss: -1035.8915, Accuracy: 83.5817%, \n",
      "\t\tValidation : Loss : -885.3386, Accuracy: 86.6359%, Time: 121.5143s\n",
      "Epoch: 73/250\n",
      "Epoch : 073, Training: Loss: -1052.5662, Accuracy: 84.3510%, \n",
      "\t\tValidation : Loss : -900.1775, Accuracy: 87.5576%, Time: 121.5078s\n",
      "Epoch: 74/250\n",
      "Epoch : 074, Training: Loss: -1061.9842, Accuracy: 83.8462%, \n",
      "\t\tValidation : Loss : -910.6954, Accuracy: 87.0968%, Time: 121.5262s\n",
      "Epoch: 75/250\n",
      "Epoch : 075, Training: Loss: -1077.4776, Accuracy: 83.7500%, \n",
      "\t\tValidation : Loss : -917.5898, Accuracy: 86.1751%, Time: 121.5527s\n",
      "Epoch: 76/250\n",
      "Epoch : 076, Training: Loss: -1093.3566, Accuracy: 84.2788%, \n",
      "\t\tValidation : Loss : -935.4058, Accuracy: 86.6359%, Time: 121.4876s\n",
      "Epoch: 77/250\n",
      "Epoch : 077, Training: Loss: -1109.3130, Accuracy: 84.2788%, \n",
      "\t\tValidation : Loss : -946.4882, Accuracy: 86.1751%, Time: 121.4503s\n",
      "Epoch: 78/250\n",
      "Epoch : 078, Training: Loss: -1119.9882, Accuracy: 84.2548%, \n",
      "\t\tValidation : Loss : -959.2514, Accuracy: 86.6359%, Time: 121.5318s\n",
      "Epoch: 79/250\n",
      "Epoch : 079, Training: Loss: -1136.4403, Accuracy: 83.5817%, \n",
      "\t\tValidation : Loss : -964.4810, Accuracy: 87.0968%, Time: 121.7508s\n",
      "Epoch: 80/250\n",
      "Epoch : 080, Training: Loss: -1149.7150, Accuracy: 84.0625%, \n",
      "\t\tValidation : Loss : -975.5580, Accuracy: 87.0968%, Time: 121.7013s\n",
      "Epoch: 81/250\n",
      "Epoch : 081, Training: Loss: -1167.7572, Accuracy: 83.3413%, \n",
      "\t\tValidation : Loss : -990.9927, Accuracy: 87.0968%, Time: 121.5401s\n",
      "Epoch: 82/250\n",
      "Epoch : 082, Training: Loss: -1178.0647, Accuracy: 83.6779%, \n",
      "\t\tValidation : Loss : -1003.5337, Accuracy: 87.0968%, Time: 121.4973s\n",
      "Epoch: 83/250\n",
      "Epoch : 083, Training: Loss: -1192.2897, Accuracy: 83.9904%, \n",
      "\t\tValidation : Loss : -1020.8418, Accuracy: 86.6359%, Time: 121.5200s\n",
      "Epoch: 84/250\n",
      "Epoch : 084, Training: Loss: -1206.8244, Accuracy: 83.7740%, \n",
      "\t\tValidation : Loss : -1027.1555, Accuracy: 87.5576%, Time: 121.5798s\n",
      "Epoch: 85/250\n",
      "Epoch : 085, Training: Loss: -1221.1378, Accuracy: 83.6779%, \n",
      "\t\tValidation : Loss : -1044.1002, Accuracy: 86.1751%, Time: 121.7665s\n",
      "Epoch: 86/250\n",
      "Epoch : 086, Training: Loss: -1236.5749, Accuracy: 83.9423%, \n",
      "\t\tValidation : Loss : -1055.8990, Accuracy: 86.6359%, Time: 121.5837s\n",
      "Epoch: 87/250\n",
      "Epoch : 087, Training: Loss: -1250.6322, Accuracy: 83.6058%, \n",
      "\t\tValidation : Loss : -1062.2584, Accuracy: 86.6359%, Time: 121.5306s\n",
      "Epoch: 88/250\n",
      "Epoch : 088, Training: Loss: -1265.4443, Accuracy: 83.8462%, \n",
      "\t\tValidation : Loss : -1078.6321, Accuracy: 85.7143%, Time: 121.5334s\n",
      "Epoch: 89/250\n",
      "Epoch : 089, Training: Loss: -1276.5380, Accuracy: 84.0144%, \n",
      "\t\tValidation : Loss : -1085.7521, Accuracy: 86.1751%, Time: 121.6364s\n",
      "Epoch: 90/250\n",
      "Epoch : 090, Training: Loss: -1292.9736, Accuracy: 83.5817%, \n",
      "\t\tValidation : Loss : -1099.2116, Accuracy: 86.1751%, Time: 121.7236s\n",
      "Epoch: 91/250\n",
      "Epoch : 091, Training: Loss: -1302.7974, Accuracy: 84.6635%, \n",
      "\t\tValidation : Loss : -1115.8143, Accuracy: 86.1751%, Time: 121.5737s\n",
      "Epoch: 92/250\n",
      "Epoch : 092, Training: Loss: -1321.5707, Accuracy: 83.6298%, \n",
      "\t\tValidation : Loss : -1129.8472, Accuracy: 86.6359%, Time: 121.6223s\n",
      "Epoch: 93/250\n",
      "Epoch : 093, Training: Loss: -1336.5545, Accuracy: 84.2308%, \n",
      "\t\tValidation : Loss : -1136.7134, Accuracy: 86.6359%, Time: 121.5941s\n",
      "Epoch: 94/250\n",
      "Epoch : 094, Training: Loss: -1351.8776, Accuracy: 83.4615%, \n",
      "\t\tValidation : Loss : -1145.6684, Accuracy: 86.6359%, Time: 121.7369s\n",
      "Epoch: 95/250\n",
      "Epoch : 095, Training: Loss: -1363.5084, Accuracy: 83.2933%, \n",
      "\t\tValidation : Loss : -1156.6408, Accuracy: 85.7143%, Time: 121.7164s\n",
      "Epoch: 96/250\n",
      "Epoch : 096, Training: Loss: -1378.1634, Accuracy: 83.9904%, \n",
      "\t\tValidation : Loss : -1176.0276, Accuracy: 86.6359%, Time: 121.5643s\n",
      "Epoch: 97/250\n",
      "Epoch : 097, Training: Loss: -1386.6053, Accuracy: 83.7981%, \n",
      "\t\tValidation : Loss : -1183.1930, Accuracy: 86.6359%, Time: 121.5449s\n",
      "Epoch: 98/250\n",
      "Epoch : 098, Training: Loss: -1410.9405, Accuracy: 84.3990%, \n",
      "\t\tValidation : Loss : -1195.7011, Accuracy: 87.0968%, Time: 121.5762s\n",
      "Epoch: 99/250\n",
      "Epoch : 099, Training: Loss: -1425.4585, Accuracy: 84.3269%, \n",
      "\t\tValidation : Loss : -1213.5000, Accuracy: 86.6359%, Time: 121.5971s\n",
      "Epoch: 100/250\n",
      "Epoch : 100, Training: Loss: -1437.6291, Accuracy: 83.7981%, \n",
      "\t\tValidation : Loss : -1226.2859, Accuracy: 86.6359%, Time: 121.5691s\n",
      "Epoch: 101/250\n",
      "Epoch : 101, Training: Loss: -1450.3762, Accuracy: 84.3990%, \n",
      "\t\tValidation : Loss : -1243.2078, Accuracy: 86.6359%, Time: 121.6607s\n",
      "Epoch: 102/250\n",
      "Epoch : 102, Training: Loss: -1466.5308, Accuracy: 83.6298%, \n",
      "\t\tValidation : Loss : -1249.5470, Accuracy: 87.5576%, Time: 121.5850s\n",
      "Epoch: 103/250\n",
      "Epoch : 103, Training: Loss: -1480.7687, Accuracy: 83.4135%, \n",
      "\t\tValidation : Loss : -1259.6203, Accuracy: 87.0968%, Time: 121.5808s\n",
      "Epoch: 104/250\n",
      "Epoch : 104, Training: Loss: -1493.5183, Accuracy: 84.4471%, \n",
      "\t\tValidation : Loss : -1267.6688, Accuracy: 87.5576%, Time: 121.7531s\n",
      "Epoch: 105/250\n",
      "Epoch : 105, Training: Loss: -1507.3797, Accuracy: 83.9663%, \n",
      "\t\tValidation : Loss : -1283.5975, Accuracy: 87.5576%, Time: 121.7437s\n",
      "Epoch: 106/250\n",
      "Epoch : 106, Training: Loss: -1523.6703, Accuracy: 83.7740%, \n",
      "\t\tValidation : Loss : -1287.6342, Accuracy: 86.1751%, Time: 121.5795s\n",
      "Epoch: 107/250\n",
      "Epoch : 107, Training: Loss: -1535.1028, Accuracy: 84.1106%, \n",
      "\t\tValidation : Loss : -1301.4450, Accuracy: 87.5576%, Time: 121.5064s\n",
      "Epoch: 108/250\n",
      "Epoch : 108, Training: Loss: -1549.5525, Accuracy: 83.7981%, \n",
      "\t\tValidation : Loss : -1324.3859, Accuracy: 87.5576%, Time: 121.5898s\n",
      "Epoch: 109/250\n",
      "Epoch : 109, Training: Loss: -1566.5079, Accuracy: 84.3029%, \n",
      "\t\tValidation : Loss : -1338.5239, Accuracy: 86.6359%, Time: 121.7758s\n",
      "Epoch: 110/250\n",
      "Epoch : 110, Training: Loss: -1578.9115, Accuracy: 83.6779%, \n",
      "\t\tValidation : Loss : -1340.3359, Accuracy: 87.0968%, Time: 121.6955s\n",
      "Epoch: 111/250\n",
      "Epoch : 111, Training: Loss: -1594.5641, Accuracy: 83.7740%, \n",
      "\t\tValidation : Loss : -1363.3928, Accuracy: 87.0968%, Time: 121.5571s\n",
      "Epoch: 112/250\n",
      "Epoch : 112, Training: Loss: -1614.0949, Accuracy: 83.5577%, \n",
      "\t\tValidation : Loss : -1363.8455, Accuracy: 87.5576%, Time: 121.5812s\n",
      "Epoch: 113/250\n",
      "Epoch : 113, Training: Loss: -1620.6871, Accuracy: 84.3029%, \n",
      "\t\tValidation : Loss : -1375.4076, Accuracy: 87.0968%, Time: 121.5459s\n",
      "Epoch: 114/250\n",
      "Epoch : 114, Training: Loss: -1633.9849, Accuracy: 84.2788%, \n",
      "\t\tValidation : Loss : -1394.6646, Accuracy: 86.6359%, Time: 121.7480s\n",
      "Epoch: 115/250\n",
      "Epoch : 115, Training: Loss: -1652.5222, Accuracy: 84.3990%, \n",
      "\t\tValidation : Loss : -1403.0580, Accuracy: 87.0968%, Time: 121.6819s\n",
      "Epoch: 116/250\n",
      "Epoch : 116, Training: Loss: -1661.8676, Accuracy: 83.2452%, \n",
      "\t\tValidation : Loss : -1415.9243, Accuracy: 87.5576%, Time: 121.5803s\n",
      "Epoch: 117/250\n",
      "Epoch : 117, Training: Loss: -1681.2508, Accuracy: 84.1827%, \n",
      "\t\tValidation : Loss : -1423.6199, Accuracy: 88.0184%, Time: 121.5792s\n",
      "Epoch: 118/250\n",
      "Epoch : 118, Training: Loss: -1694.6184, Accuracy: 84.2067%, \n",
      "\t\tValidation : Loss : -1439.0200, Accuracy: 87.0968%, Time: 121.5429s\n",
      "Epoch: 119/250\n",
      "Epoch : 119, Training: Loss: -1705.1987, Accuracy: 83.1971%, \n",
      "\t\tValidation : Loss : -1463.2323, Accuracy: 86.6359%, Time: 121.8107s\n",
      "Epoch: 120/250\n",
      "Epoch : 120, Training: Loss: -1717.8335, Accuracy: 84.5433%, \n",
      "\t\tValidation : Loss : -1465.9900, Accuracy: 86.6359%, Time: 121.5669s\n",
      "Epoch: 121/250\n",
      "Epoch : 121, Training: Loss: -1736.8689, Accuracy: 85.2885%, \n",
      "\t\tValidation : Loss : -1481.3825, Accuracy: 87.5576%, Time: 121.6447s\n",
      "Epoch: 122/250\n",
      "Epoch : 122, Training: Loss: -1751.8122, Accuracy: 84.0144%, \n",
      "\t\tValidation : Loss : -1493.1820, Accuracy: 87.0968%, Time: 121.6324s\n",
      "Epoch: 123/250\n",
      "Epoch : 123, Training: Loss: -1762.9732, Accuracy: 82.9087%, \n",
      "\t\tValidation : Loss : -1509.8405, Accuracy: 87.5576%, Time: 121.5853s\n",
      "Epoch: 124/250\n",
      "Epoch : 124, Training: Loss: -1778.5364, Accuracy: 84.1346%, \n",
      "\t\tValidation : Loss : -1506.0711, Accuracy: 86.6359%, Time: 121.6430s\n",
      "Epoch: 125/250\n",
      "Epoch : 125, Training: Loss: -1796.0123, Accuracy: 83.9904%, \n",
      "\t\tValidation : Loss : -1519.4766, Accuracy: 86.6359%, Time: 121.5953s\n",
      "Epoch: 126/250\n",
      "Epoch : 126, Training: Loss: -1806.3141, Accuracy: 84.0385%, \n",
      "\t\tValidation : Loss : -1532.6015, Accuracy: 86.6359%, Time: 121.5910s\n",
      "Epoch: 127/250\n",
      "Epoch : 127, Training: Loss: -1824.7538, Accuracy: 84.4231%, \n",
      "\t\tValidation : Loss : -1554.3644, Accuracy: 87.0968%, Time: 121.5706s\n",
      "Epoch: 128/250\n",
      "Epoch : 128, Training: Loss: -1837.4194, Accuracy: 83.1971%, \n",
      "\t\tValidation : Loss : -1553.9442, Accuracy: 86.1751%, Time: 121.5539s\n",
      "Epoch: 129/250\n",
      "Epoch : 129, Training: Loss: -1850.1111, Accuracy: 84.3510%, \n",
      "\t\tValidation : Loss : -1568.6448, Accuracy: 86.1751%, Time: 121.8428s\n",
      "Epoch: 130/250\n",
      "Epoch : 130, Training: Loss: -1863.5439, Accuracy: 84.0625%, \n",
      "\t\tValidation : Loss : -1583.1995, Accuracy: 86.6359%, Time: 121.6739s\n",
      "Epoch: 131/250\n",
      "Epoch : 131, Training: Loss: -1878.2783, Accuracy: 83.9904%, \n",
      "\t\tValidation : Loss : -1589.9256, Accuracy: 87.0968%, Time: 121.5844s\n",
      "Epoch: 132/250\n",
      "Epoch : 132, Training: Loss: -1889.2966, Accuracy: 83.7500%, \n",
      "\t\tValidation : Loss : -1607.8682, Accuracy: 86.6359%, Time: 121.5272s\n",
      "Epoch: 133/250\n",
      "Epoch : 133, Training: Loss: -1906.8859, Accuracy: 83.9423%, \n",
      "\t\tValidation : Loss : -1623.9369, Accuracy: 87.5576%, Time: 121.5680s\n",
      "Epoch: 134/250\n",
      "Epoch : 134, Training: Loss: -1917.7632, Accuracy: 83.5577%, \n",
      "\t\tValidation : Loss : -1642.3440, Accuracy: 87.5576%, Time: 121.7982s\n",
      "Epoch: 135/250\n",
      "Epoch : 135, Training: Loss: -1938.0403, Accuracy: 83.7260%, \n",
      "\t\tValidation : Loss : -1647.0677, Accuracy: 86.1751%, Time: 121.5011s\n",
      "Epoch: 136/250\n",
      "Epoch : 136, Training: Loss: -1947.5977, Accuracy: 83.9904%, \n",
      "\t\tValidation : Loss : -1657.9281, Accuracy: 87.0968%, Time: 121.5044s\n",
      "Epoch: 137/250\n",
      "Epoch : 137, Training: Loss: -1967.4236, Accuracy: 84.1587%, \n",
      "\t\tValidation : Loss : -1672.0388, Accuracy: 86.6359%, Time: 121.5761s\n",
      "Epoch: 138/250\n",
      "Epoch : 138, Training: Loss: -1973.0412, Accuracy: 84.1587%, \n",
      "\t\tValidation : Loss : -1670.0679, Accuracy: 86.6359%, Time: 121.6620s\n",
      "Epoch: 139/250\n",
      "Epoch : 139, Training: Loss: -1993.8512, Accuracy: 83.8462%, \n",
      "\t\tValidation : Loss : -1700.6637, Accuracy: 87.0968%, Time: 121.7987s\n",
      "Epoch: 140/250\n",
      "Epoch : 140, Training: Loss: -2014.5155, Accuracy: 83.8702%, \n",
      "\t\tValidation : Loss : -1712.9176, Accuracy: 86.6359%, Time: 121.5343s\n",
      "Epoch: 141/250\n",
      "Epoch : 141, Training: Loss: -2020.4191, Accuracy: 84.3269%, \n",
      "\t\tValidation : Loss : -1720.6062, Accuracy: 87.5576%, Time: 121.4948s\n",
      "Epoch: 142/250\n",
      "Epoch : 142, Training: Loss: -2030.1984, Accuracy: 84.0144%, \n",
      "\t\tValidation : Loss : -1728.5201, Accuracy: 86.6359%, Time: 121.5877s\n",
      "Epoch: 143/250\n",
      "Epoch : 143, Training: Loss: -2046.2419, Accuracy: 83.6779%, \n",
      "\t\tValidation : Loss : -1740.2359, Accuracy: 86.6359%, Time: 121.7241s\n",
      "Epoch: 144/250\n",
      "Epoch : 144, Training: Loss: -2068.4827, Accuracy: 83.8702%, \n",
      "\t\tValidation : Loss : -1760.1075, Accuracy: 87.5576%, Time: 121.6777s\n",
      "Epoch: 145/250\n",
      "Epoch : 145, Training: Loss: -2074.4103, Accuracy: 83.6779%, \n",
      "\t\tValidation : Loss : -1761.0099, Accuracy: 86.6359%, Time: 121.6818s\n",
      "Epoch: 146/250\n",
      "Epoch : 146, Training: Loss: -2094.7883, Accuracy: 83.4135%, \n",
      "\t\tValidation : Loss : -1786.7970, Accuracy: 86.6359%, Time: 121.5721s\n",
      "Epoch: 147/250\n",
      "Epoch : 147, Training: Loss: -2110.2722, Accuracy: 84.4712%, \n",
      "\t\tValidation : Loss : -1782.2727, Accuracy: 87.0968%, Time: 121.5792s\n",
      "Epoch: 148/250\n",
      "Epoch : 148, Training: Loss: -2124.6238, Accuracy: 84.1827%, \n",
      "\t\tValidation : Loss : -1807.2824, Accuracy: 87.0968%, Time: 121.5311s\n",
      "Epoch: 149/250\n",
      "Epoch : 149, Training: Loss: -2141.5920, Accuracy: 84.8077%, \n",
      "\t\tValidation : Loss : -1824.9052, Accuracy: 87.5576%, Time: 121.5321s\n",
      "Epoch: 150/250\n",
      "Epoch : 150, Training: Loss: -2146.2537, Accuracy: 83.6779%, \n",
      "\t\tValidation : Loss : -1835.2612, Accuracy: 87.5576%, Time: 121.6059s\n",
      "Epoch: 151/250\n",
      "Epoch : 151, Training: Loss: -2167.3322, Accuracy: 83.6779%, \n",
      "\t\tValidation : Loss : -1847.5367, Accuracy: 87.0968%, Time: 121.5789s\n",
      "Epoch: 152/250\n",
      "Epoch : 152, Training: Loss: -2179.5254, Accuracy: 83.8942%, \n",
      "\t\tValidation : Loss : -1855.8320, Accuracy: 87.5576%, Time: 121.6855s\n",
      "Epoch: 153/250\n",
      "Epoch : 153, Training: Loss: -2195.5914, Accuracy: 84.1106%, \n",
      "\t\tValidation : Loss : -1883.4455, Accuracy: 85.7143%, Time: 121.6951s\n",
      "Epoch: 154/250\n",
      "Epoch : 154, Training: Loss: -2207.3983, Accuracy: 83.8702%, \n",
      "\t\tValidation : Loss : -1870.0859, Accuracy: 86.1751%, Time: 121.8293s\n",
      "Epoch: 155/250\n",
      "Epoch : 155, Training: Loss: -2215.7340, Accuracy: 83.3654%, \n",
      "\t\tValidation : Loss : -1890.0995, Accuracy: 87.5576%, Time: 121.5723s\n",
      "Epoch: 156/250\n",
      "Epoch : 156, Training: Loss: -2236.2738, Accuracy: 83.1490%, \n",
      "\t\tValidation : Loss : -1908.6253, Accuracy: 87.0968%, Time: 121.6124s\n",
      "Epoch: 157/250\n",
      "Epoch : 157, Training: Loss: -2249.5636, Accuracy: 83.5577%, \n",
      "\t\tValidation : Loss : -1908.2324, Accuracy: 87.0968%, Time: 121.6021s\n",
      "Epoch: 158/250\n",
      "Epoch : 158, Training: Loss: -2265.8398, Accuracy: 84.5673%, \n",
      "\t\tValidation : Loss : -1926.2987, Accuracy: 86.6359%, Time: 121.7464s\n",
      "Epoch: 159/250\n",
      "Epoch : 159, Training: Loss: -2277.4973, Accuracy: 84.0385%, \n",
      "\t\tValidation : Loss : -1929.8589, Accuracy: 86.6359%, Time: 121.7783s\n",
      "Epoch: 160/250\n",
      "Epoch : 160, Training: Loss: -2297.1834, Accuracy: 83.4856%, \n",
      "\t\tValidation : Loss : -1946.8103, Accuracy: 87.0968%, Time: 121.6461s\n",
      "Epoch: 161/250\n",
      "Epoch : 161, Training: Loss: -2303.6644, Accuracy: 83.4856%, \n",
      "\t\tValidation : Loss : -1963.7913, Accuracy: 86.6359%, Time: 121.5917s\n",
      "Epoch: 162/250\n",
      "Epoch : 162, Training: Loss: -2321.4473, Accuracy: 83.5817%, \n",
      "\t\tValidation : Loss : -1983.7599, Accuracy: 87.0968%, Time: 121.5756s\n",
      "Epoch: 163/250\n",
      "Epoch : 163, Training: Loss: -2335.0359, Accuracy: 83.9183%, \n",
      "\t\tValidation : Loss : -1985.1706, Accuracy: 87.0968%, Time: 121.7773s\n",
      "Epoch: 164/250\n",
      "Epoch : 164, Training: Loss: -2345.7978, Accuracy: 84.3029%, \n",
      "\t\tValidation : Loss : -2001.6650, Accuracy: 87.0968%, Time: 121.7608s\n",
      "Epoch: 165/250\n",
      "Epoch : 165, Training: Loss: -2356.4624, Accuracy: 83.7740%, \n",
      "\t\tValidation : Loss : -2003.3769, Accuracy: 86.1751%, Time: 121.5937s\n",
      "Epoch: 166/250\n",
      "Epoch : 166, Training: Loss: -2385.1701, Accuracy: 83.9663%, \n",
      "\t\tValidation : Loss : -2016.3367, Accuracy: 86.1751%, Time: 121.6387s\n",
      "Epoch: 167/250\n",
      "Epoch : 167, Training: Loss: -2387.6398, Accuracy: 83.8702%, \n",
      "\t\tValidation : Loss : -2040.8552, Accuracy: 86.6359%, Time: 121.7281s\n",
      "Epoch: 168/250\n",
      "Epoch : 168, Training: Loss: -2411.3128, Accuracy: 83.4135%, \n",
      "\t\tValidation : Loss : -2058.8952, Accuracy: 87.0968%, Time: 121.7117s\n",
      "Epoch: 169/250\n",
      "Epoch : 169, Training: Loss: -2419.3235, Accuracy: 84.0385%, \n",
      "\t\tValidation : Loss : -2070.9935, Accuracy: 87.0968%, Time: 121.8395s\n",
      "Epoch: 170/250\n",
      "Epoch : 170, Training: Loss: -2443.2969, Accuracy: 83.8942%, \n",
      "\t\tValidation : Loss : -2067.6812, Accuracy: 87.0968%, Time: 121.6242s\n",
      "Epoch: 171/250\n",
      "Epoch : 171, Training: Loss: -2449.7159, Accuracy: 83.4615%, \n",
      "\t\tValidation : Loss : -2081.5049, Accuracy: 87.5576%, Time: 121.5750s\n",
      "Epoch: 172/250\n",
      "Epoch : 172, Training: Loss: -2464.4120, Accuracy: 83.4615%, \n",
      "\t\tValidation : Loss : -2069.8272, Accuracy: 87.0968%, Time: 121.6370s\n",
      "Epoch: 173/250\n",
      "Epoch : 173, Training: Loss: -2481.6724, Accuracy: 83.6058%, \n",
      "\t\tValidation : Loss : -2103.4874, Accuracy: 86.1751%, Time: 121.5666s\n",
      "Epoch: 174/250\n",
      "Epoch : 174, Training: Loss: -2490.4470, Accuracy: 84.2308%, \n",
      "\t\tValidation : Loss : -2128.3185, Accuracy: 87.0968%, Time: 121.6346s\n",
      "Epoch: 175/250\n",
      "Epoch : 175, Training: Loss: -2500.8800, Accuracy: 83.6538%, \n",
      "\t\tValidation : Loss : -2127.0394, Accuracy: 86.1751%, Time: 121.7193s\n",
      "Epoch: 176/250\n",
      "Epoch : 176, Training: Loss: -2522.0571, Accuracy: 83.4856%, \n",
      "\t\tValidation : Loss : -2144.0680, Accuracy: 86.1751%, Time: 121.6805s\n",
      "Epoch: 177/250\n",
      "Epoch : 177, Training: Loss: -2535.1409, Accuracy: 83.4615%, \n",
      "\t\tValidation : Loss : -2160.1265, Accuracy: 87.0968%, Time: 121.6015s\n",
      "Epoch: 178/250\n",
      "Epoch : 178, Training: Loss: -2550.7896, Accuracy: 84.3510%, \n",
      "\t\tValidation : Loss : -2177.0139, Accuracy: 86.6359%, Time: 121.8612s\n",
      "Epoch: 179/250\n",
      "Epoch : 179, Training: Loss: -2562.6010, Accuracy: 84.0144%, \n",
      "\t\tValidation : Loss : -2185.1255, Accuracy: 86.6359%, Time: 121.6978s\n",
      "Epoch: 180/250\n",
      "Epoch : 180, Training: Loss: -2573.9530, Accuracy: 83.9183%, \n",
      "\t\tValidation : Loss : -2214.6515, Accuracy: 86.6359%, Time: 121.6761s\n",
      "Epoch: 181/250\n",
      "Epoch : 181, Training: Loss: -2592.0072, Accuracy: 84.0625%, \n",
      "\t\tValidation : Loss : -2209.2309, Accuracy: 86.6359%, Time: 121.6786s\n",
      "Epoch: 182/250\n",
      "Epoch : 182, Training: Loss: -2613.5850, Accuracy: 84.4471%, \n",
      "\t\tValidation : Loss : -2221.7462, Accuracy: 87.5576%, Time: 121.7141s\n",
      "Epoch: 183/250\n",
      "Epoch : 183, Training: Loss: -2614.2918, Accuracy: 83.8462%, \n",
      "\t\tValidation : Loss : -2245.3046, Accuracy: 87.0968%, Time: 121.8847s\n",
      "Epoch: 184/250\n",
      "Epoch : 184, Training: Loss: -2641.0012, Accuracy: 83.6298%, \n",
      "\t\tValidation : Loss : -2241.0746, Accuracy: 85.7143%, Time: 121.7180s\n",
      "Epoch: 185/250\n",
      "Epoch : 185, Training: Loss: -2650.3354, Accuracy: 83.8462%, \n",
      "\t\tValidation : Loss : -2250.3551, Accuracy: 87.0968%, Time: 121.6122s\n",
      "Epoch: 186/250\n",
      "Epoch : 186, Training: Loss: -2674.7189, Accuracy: 83.6298%, \n",
      "\t\tValidation : Loss : -2261.9741, Accuracy: 86.6359%, Time: 121.6333s\n",
      "Epoch: 187/250\n",
      "Epoch : 187, Training: Loss: -2676.2165, Accuracy: 84.3510%, \n",
      "\t\tValidation : Loss : -2278.6075, Accuracy: 86.6359%, Time: 121.5850s\n",
      "Epoch: 188/250\n",
      "Epoch : 188, Training: Loss: -2695.3822, Accuracy: 83.2692%, \n",
      "\t\tValidation : Loss : -2292.8322, Accuracy: 86.1751%, Time: 121.7286s\n",
      "Epoch: 189/250\n",
      "Epoch : 189, Training: Loss: -2704.3864, Accuracy: 83.5817%, \n",
      "\t\tValidation : Loss : -2309.7195, Accuracy: 86.6359%, Time: 121.8042s\n",
      "Epoch: 190/250\n",
      "Epoch : 190, Training: Loss: -2721.5936, Accuracy: 84.1106%, \n",
      "\t\tValidation : Loss : -2309.5151, Accuracy: 86.1751%, Time: 121.6564s\n",
      "Epoch: 191/250\n",
      "Epoch : 191, Training: Loss: -2732.7216, Accuracy: 84.4471%, \n",
      "\t\tValidation : Loss : -2322.0083, Accuracy: 87.0968%, Time: 121.6275s\n",
      "Epoch: 192/250\n",
      "Epoch : 192, Training: Loss: -2751.7184, Accuracy: 84.1106%, \n",
      "\t\tValidation : Loss : -2339.6606, Accuracy: 86.6359%, Time: 121.6245s\n",
      "Epoch: 193/250\n",
      "Epoch : 193, Training: Loss: -2759.4577, Accuracy: 83.9904%, \n",
      "\t\tValidation : Loss : -2346.9855, Accuracy: 86.6359%, Time: 121.8123s\n",
      "Epoch: 194/250\n",
      "Epoch : 194, Training: Loss: -2770.6431, Accuracy: 83.8942%, \n",
      "\t\tValidation : Loss : -2356.5723, Accuracy: 86.6359%, Time: 121.6784s\n",
      "Epoch: 195/250\n",
      "Epoch : 195, Training: Loss: -2790.1891, Accuracy: 82.9567%, \n",
      "\t\tValidation : Loss : -2370.2084, Accuracy: 87.0968%, Time: 121.6463s\n",
      "Epoch: 196/250\n",
      "Epoch : 196, Training: Loss: -2810.8020, Accuracy: 84.4952%, \n",
      "\t\tValidation : Loss : -2382.2243, Accuracy: 87.5576%, Time: 121.6396s\n",
      "Epoch: 197/250\n",
      "Epoch : 197, Training: Loss: -2825.3332, Accuracy: 83.7260%, \n",
      "\t\tValidation : Loss : -2391.0965, Accuracy: 86.6359%, Time: 121.6611s\n",
      "Epoch: 198/250\n",
      "Epoch : 198, Training: Loss: -2831.5394, Accuracy: 84.0385%, \n",
      "\t\tValidation : Loss : -2407.0183, Accuracy: 86.1751%, Time: 121.6015s\n",
      "Epoch: 199/250\n",
      "Epoch : 199, Training: Loss: -2851.8450, Accuracy: 84.3750%, \n",
      "\t\tValidation : Loss : -2428.4300, Accuracy: 86.1751%, Time: 121.6518s\n",
      "Epoch: 200/250\n",
      "Epoch : 200, Training: Loss: -2871.5541, Accuracy: 85.1683%, \n",
      "\t\tValidation : Loss : -2459.9468, Accuracy: 86.1751%, Time: 121.6259s\n",
      "Epoch: 201/250\n",
      "Epoch : 201, Training: Loss: -2880.7829, Accuracy: 83.5096%, \n",
      "\t\tValidation : Loss : -2447.0234, Accuracy: 87.0968%, Time: 121.6233s\n",
      "Epoch: 202/250\n",
      "Epoch : 202, Training: Loss: -2887.1102, Accuracy: 85.1683%, \n",
      "\t\tValidation : Loss : -2455.9946, Accuracy: 87.5576%, Time: 121.6886s\n",
      "Epoch: 203/250\n",
      "Epoch : 203, Training: Loss: -2906.8782, Accuracy: 84.4471%, \n",
      "\t\tValidation : Loss : -2482.9577, Accuracy: 87.5576%, Time: 121.9405s\n",
      "Epoch: 204/250\n",
      "Epoch : 204, Training: Loss: -2920.1402, Accuracy: 83.9423%, \n",
      "\t\tValidation : Loss : -2490.1346, Accuracy: 87.0968%, Time: 121.7199s\n",
      "Epoch: 205/250\n",
      "Epoch : 205, Training: Loss: -2933.7350, Accuracy: 83.7260%, \n",
      "\t\tValidation : Loss : -2481.5589, Accuracy: 86.1751%, Time: 121.7196s\n",
      "Epoch: 206/250\n",
      "Epoch : 206, Training: Loss: -2952.9117, Accuracy: 83.8942%, \n",
      "\t\tValidation : Loss : -2505.1691, Accuracy: 86.6359%, Time: 121.6797s\n",
      "Epoch: 207/250\n",
      "Epoch : 207, Training: Loss: -2963.3825, Accuracy: 83.2452%, \n",
      "\t\tValidation : Loss : -2525.8515, Accuracy: 87.5576%, Time: 121.6393s\n",
      "Epoch: 208/250\n",
      "Epoch : 208, Training: Loss: -2983.5656, Accuracy: 83.4375%, \n",
      "\t\tValidation : Loss : -2524.9631, Accuracy: 87.0968%, Time: 121.9526s\n",
      "Epoch: 209/250\n",
      "Epoch : 209, Training: Loss: -3000.4027, Accuracy: 83.8221%, \n",
      "\t\tValidation : Loss : -2535.7884, Accuracy: 87.0968%, Time: 121.7832s\n",
      "Epoch: 210/250\n",
      "Epoch : 210, Training: Loss: -3015.3509, Accuracy: 83.5096%, \n",
      "\t\tValidation : Loss : -2562.1254, Accuracy: 86.6359%, Time: 121.6555s\n",
      "Epoch: 211/250\n",
      "Epoch : 211, Training: Loss: -3024.0376, Accuracy: 84.3029%, \n",
      "\t\tValidation : Loss : -2574.2972, Accuracy: 87.0968%, Time: 121.6850s\n",
      "Epoch: 212/250\n",
      "Epoch : 212, Training: Loss: -3044.0535, Accuracy: 84.8558%, \n",
      "\t\tValidation : Loss : -2596.5150, Accuracy: 86.6359%, Time: 121.7103s\n",
      "Epoch: 213/250\n",
      "Epoch : 213, Training: Loss: -3054.2289, Accuracy: 83.7740%, \n",
      "\t\tValidation : Loss : -2580.4334, Accuracy: 87.5576%, Time: 122.0161s\n",
      "Epoch: 214/250\n",
      "Epoch : 214, Training: Loss: -3066.5678, Accuracy: 83.5096%, \n",
      "\t\tValidation : Loss : -2615.2997, Accuracy: 87.5576%, Time: 121.7183s\n",
      "Epoch: 215/250\n",
      "Epoch : 215, Training: Loss: -3078.1248, Accuracy: 84.1346%, \n",
      "\t\tValidation : Loss : -2616.3398, Accuracy: 86.6359%, Time: 121.6781s\n",
      "Epoch: 216/250\n",
      "Epoch : 216, Training: Loss: -3089.7193, Accuracy: 84.3029%, \n",
      "\t\tValidation : Loss : -2631.2972, Accuracy: 88.0184%, Time: 121.6428s\n",
      "Epoch: 217/250\n",
      "Epoch : 217, Training: Loss: -3109.6984, Accuracy: 83.7981%, \n",
      "\t\tValidation : Loss : -2656.8944, Accuracy: 85.7143%, Time: 121.7768s\n",
      "Epoch: 218/250\n",
      "Epoch : 218, Training: Loss: -3121.7418, Accuracy: 83.7260%, \n",
      "\t\tValidation : Loss : -2668.9487, Accuracy: 86.6359%, Time: 122.0381s\n",
      "Epoch: 219/250\n",
      "Epoch : 219, Training: Loss: -3136.5875, Accuracy: 84.0865%, \n",
      "\t\tValidation : Loss : -2666.4398, Accuracy: 87.0968%, Time: 121.8017s\n",
      "Epoch: 220/250\n",
      "Epoch : 220, Training: Loss: -3149.8981, Accuracy: 85.0240%, \n",
      "\t\tValidation : Loss : -2679.5020, Accuracy: 87.0968%, Time: 121.6376s\n",
      "Epoch: 221/250\n",
      "Epoch : 221, Training: Loss: -3162.9284, Accuracy: 83.8221%, \n",
      "\t\tValidation : Loss : -2683.5373, Accuracy: 86.6359%, Time: 121.6428s\n",
      "Epoch: 222/250\n",
      "Epoch : 222, Training: Loss: -3184.8769, Accuracy: 84.1106%, \n",
      "\t\tValidation : Loss : -2711.8969, Accuracy: 86.6359%, Time: 121.6418s\n",
      "Epoch: 223/250\n",
      "Epoch : 223, Training: Loss: -3194.3326, Accuracy: 84.1827%, \n",
      "\t\tValidation : Loss : -2705.5798, Accuracy: 86.6359%, Time: 121.5990s\n",
      "Epoch: 224/250\n",
      "Epoch : 224, Training: Loss: -3207.5134, Accuracy: 85.4327%, \n",
      "\t\tValidation : Loss : -2738.0022, Accuracy: 87.5576%, Time: 121.6072s\n",
      "Epoch: 225/250\n",
      "Epoch : 225, Training: Loss: -3226.9205, Accuracy: 84.4712%, \n",
      "\t\tValidation : Loss : -2732.1937, Accuracy: 87.0968%, Time: 121.6108s\n",
      "Epoch: 226/250\n",
      "Epoch : 226, Training: Loss: -3235.5201, Accuracy: 84.3510%, \n",
      "\t\tValidation : Loss : -2751.7120, Accuracy: 87.0968%, Time: 121.6375s\n",
      "Epoch: 227/250\n",
      "Epoch : 227, Training: Loss: -3255.2662, Accuracy: 84.6154%, \n",
      "\t\tValidation : Loss : -2759.0264, Accuracy: 86.6359%, Time: 121.6377s\n",
      "Epoch: 228/250\n",
      "Epoch : 228, Training: Loss: -3263.4800, Accuracy: 84.1827%, \n",
      "\t\tValidation : Loss : -2772.8458, Accuracy: 87.0968%, Time: 121.9479s\n",
      "Epoch: 229/250\n",
      "Epoch : 229, Training: Loss: -3276.2324, Accuracy: 84.1587%, \n",
      "\t\tValidation : Loss : -2785.5546, Accuracy: 87.0968%, Time: 121.6146s\n",
      "Epoch: 230/250\n",
      "Epoch : 230, Training: Loss: -3289.5116, Accuracy: 83.7500%, \n",
      "\t\tValidation : Loss : -2805.6685, Accuracy: 87.5576%, Time: 121.6271s\n",
      "Epoch: 231/250\n",
      "Epoch : 231, Training: Loss: -3308.1017, Accuracy: 83.7500%, \n",
      "\t\tValidation : Loss : -2830.1568, Accuracy: 87.5576%, Time: 121.6364s\n",
      "Epoch: 232/250\n",
      "Epoch : 232, Training: Loss: -3325.3638, Accuracy: 83.0048%, \n",
      "\t\tValidation : Loss : -2825.0106, Accuracy: 87.5576%, Time: 121.7419s\n",
      "Epoch: 233/250\n",
      "Epoch : 233, Training: Loss: -3334.2990, Accuracy: 83.3413%, \n",
      "\t\tValidation : Loss : -2834.9098, Accuracy: 87.0968%, Time: 121.8602s\n",
      "Epoch: 234/250\n",
      "Epoch : 234, Training: Loss: -3342.4062, Accuracy: 84.3510%, \n",
      "\t\tValidation : Loss : -2854.3645, Accuracy: 87.0968%, Time: 121.6436s\n",
      "Epoch: 235/250\n",
      "Epoch : 235, Training: Loss: -3363.1714, Accuracy: 83.1490%, \n",
      "\t\tValidation : Loss : -2866.5967, Accuracy: 86.6359%, Time: 121.6049s\n",
      "Epoch: 236/250\n",
      "Epoch : 236, Training: Loss: -3374.6237, Accuracy: 83.4856%, \n",
      "\t\tValidation : Loss : -2877.7521, Accuracy: 87.5576%, Time: 121.6365s\n",
      "Epoch: 237/250\n",
      "Epoch : 237, Training: Loss: -3388.2087, Accuracy: 84.1587%, \n",
      "\t\tValidation : Loss : -2878.8470, Accuracy: 87.0968%, Time: 121.7380s\n",
      "Epoch: 238/250\n",
      "Epoch : 238, Training: Loss: -3411.1347, Accuracy: 83.7740%, \n",
      "\t\tValidation : Loss : -2912.3344, Accuracy: 87.0968%, Time: 121.8449s\n",
      "Epoch: 239/250\n",
      "Epoch : 239, Training: Loss: -3423.3972, Accuracy: 83.7981%, \n",
      "\t\tValidation : Loss : -2920.4528, Accuracy: 87.5576%, Time: 121.6492s\n",
      "Epoch: 240/250\n",
      "Epoch : 240, Training: Loss: -3433.2528, Accuracy: 83.3894%, \n",
      "\t\tValidation : Loss : -2932.3540, Accuracy: 86.6359%, Time: 121.6379s\n",
      "Epoch: 241/250\n",
      "Epoch : 241, Training: Loss: -3447.4068, Accuracy: 83.7019%, \n",
      "\t\tValidation : Loss : -2922.2967, Accuracy: 86.6359%, Time: 121.6534s\n",
      "Epoch: 242/250\n",
      "Epoch : 242, Training: Loss: -3464.6763, Accuracy: 84.4712%, \n",
      "\t\tValidation : Loss : -2940.3077, Accuracy: 86.1751%, Time: 121.9034s\n",
      "Epoch: 243/250\n",
      "Epoch : 243, Training: Loss: -3479.5715, Accuracy: 83.7260%, \n",
      "\t\tValidation : Loss : -2938.8889, Accuracy: 86.6359%, Time: 121.8130s\n",
      "Epoch: 244/250\n",
      "Epoch : 244, Training: Loss: -3489.4125, Accuracy: 83.6779%, \n",
      "\t\tValidation : Loss : -2976.6424, Accuracy: 87.5576%, Time: 121.7211s\n",
      "Epoch: 245/250\n",
      "Epoch : 245, Training: Loss: -3501.2031, Accuracy: 83.2692%, \n",
      "\t\tValidation : Loss : -2998.0403, Accuracy: 87.5576%, Time: 121.5739s\n",
      "Epoch: 246/250\n",
      "Epoch : 246, Training: Loss: -3518.7973, Accuracy: 83.9663%, \n",
      "\t\tValidation : Loss : -2978.8646, Accuracy: 87.5576%, Time: 121.5959s\n",
      "Epoch: 247/250\n",
      "Epoch : 247, Training: Loss: -3534.8359, Accuracy: 83.1731%, \n",
      "\t\tValidation : Loss : -2984.9886, Accuracy: 86.1751%, Time: 121.7754s\n",
      "Epoch: 248/250\n",
      "Epoch : 248, Training: Loss: -3549.4138, Accuracy: 83.7740%, \n",
      "\t\tValidation : Loss : -3022.8066, Accuracy: 87.0968%, Time: 121.7297s\n",
      "Epoch: 249/250\n",
      "Epoch : 249, Training: Loss: -3564.2278, Accuracy: 83.6779%, \n",
      "\t\tValidation : Loss : -3045.5014, Accuracy: 87.0968%, Time: 121.6925s\n",
      "Epoch: 250/250\n",
      "Epoch : 250, Training: Loss: -3586.1140, Accuracy: 83.8942%, \n",
      "\t\tValidation : Loss : -3026.5511, Accuracy: 86.1751%, Time: 121.6018s\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "efficientnet.to(device)\n",
    "num_epochs = 250\n",
    "trained_model, history = train_and_validate(efficientnet, loss_func, optimizer, num_epochs)\n",
    "torch.save(history, dataset + '_efficientnet_new250.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99cd46de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = np.array(history)\n",
    "plt.plot(history[:,0:2])\n",
    "plt.legend(['Tr Loss', 'Val Loss'])\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim(0,1)\n",
    "plt.savefig(dataset+'_loss_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c11b169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history[:,2:4])\n",
    "plt.legend(['Tr Accuracy', 'Val Accuracy'])\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0,1)\n",
    "plt.savefig(dataset+'_accuracy_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5766cc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_image_name):\n",
    "    '''\n",
    "    Function to predict the class of a single test image\n",
    "    Parameters\n",
    "        :param model: Model to test\n",
    "        :param test_image_name: Test image\n",
    "\n",
    "    '''\n",
    "    \n",
    "    transform = image_transforms['test']\n",
    "\n",
    "    test_image = Image.open(test_image_name)\n",
    "    plt.imshow(test_image)\n",
    "    \n",
    "    test_image_tensor = transform(test_image)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        test_image_tensor = test_image_tensor.view(1, 3, 224, 224).cuda()\n",
    "    else:\n",
    "        test_image_tensor = test_image_tensor.view(1, 3, 224, 224)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        # Model outputs log probabilities\n",
    "        out = model(test_image_tensor)\n",
    "        ps = torch.exp(out)\n",
    "        topk, topclass = ps.topk(5, dim=1)\n",
    "        for i in range(5):\n",
    "            print(\"Predcition\", i+1, \":\", idx_to_class[topclass.numpy()[0][i]], \", Score: \", topk.numpy()[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2378da02",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (1398007040.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [29]\u001b[1;36m\u001b[0m\n\u001b[1;33m    predict(trained_model, \"E:\\\\Cotton_data\\\\valid\\\\Aphids\\\\6.jpg\"\")\u001b[0m\n\u001b[1;37m                                                                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "predict(trained_model, \"E:\\\\Cotton_data\\\\valid\\\\Aphids\\\\6.jpg\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b753da7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
